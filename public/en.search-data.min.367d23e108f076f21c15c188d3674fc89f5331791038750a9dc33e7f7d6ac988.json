[{"id":0,"href":"/docs/tauri_diesel_sqlite/","title":"Rust: Tauri + Diesel + SQLite","section":"Docs","content":" Rust: Tauri + Diesel + SQLite # Small documentation, tips and experiences for accessing a SQLite database from Rust with the ORM library diesel.\nComplete and possibly extended code can be found in the repository archive_cat.\nRequirements # I use the following library\n[build-dependencies] tauri-build = { version = \u0026#34;1.3\u0026#34;, features = [] } [dependencies] tauri = { version = \u0026#34;1.4.1\u0026#34;, features = [\u0026#34;shell-open\u0026#34;, \u0026#34;window-close\u0026#34;] } serde = { version = \u0026#34;1.0\u0026#34;, features = [\u0026#34;derive\u0026#34;] } serde_json = { version = \u0026#34;1.0\u0026#34;, features = [\u0026#34;raw_value\u0026#34;] } home = \u0026#34;0.5.5\u0026#34; diesel = { version = \u0026#34;2.1.0\u0026#34;, features = [\u0026#34;sqlite\u0026#34;, \u0026#34;64-column-tables\u0026#34;] } dotenvy = \u0026#34;0.15.7\u0026#34; chrono = \u0026#34;0.4.26\u0026#34; url = \u0026#34;2.4.0\u0026#34; tokio = { version = \u0026#34;1.28.2\u0026#34;, features = [\u0026#34;full\u0026#34;] } tracing = \u0026#34;0.1.37\u0026#34; tracing-subscriber = \u0026#34;0.3.17\u0026#34; base64 = \u0026#34;0.21.2\u0026#34; If necessary, install the libraries with cargo add xxx.\nFor the tauri installation please look here TAURI and for diesel here diesel.rs.\nConnection with the database # The usual way is the access via a .env file. The access is somewhat dependent on the database, i.e., there are also databases that support pool-connections. For SQLite, the SqliteConnection::establish function should be used.\nExample 1.1 database.rs:\nuse std::env; use diesel::prelude::*; use dotenvy::dotenv; use tracing::info; pub fn establish_connection() -\u0026gt; SqliteConnection { info!(\u0026#34;start establish_connection()\u0026#34;,); dotenv().ok(); let database_url = env::var(\u0026#34;DATABASE_URL\u0026#34;).expect(\u0026#34;DATABASE_URL must be set\u0026#34;); SqliteConnection::establish(\u0026amp;database_url) .unwrap_or_else(|_| panic!(\u0026#34;Error connecting to the database: {}\u0026#34;, database_url)) } Here the library dotenvy is taken for loading the .env file. The variable here has the name DATABASE_URL.\nExample .env\nDATABASE_URL=sqlite:///Users/jankstar/tauri_database.db The database connection is then used as follows:\nuse crate::database::*; ... let mut conn = establish_connection(); ... Alternatively, the user\u0026rsquo;s home directory is accessed.\nExample 1.2 database.rs\nuse diesel::prelude::*; use tracing::info; use home::home_dir; pub fn establish_connection(database_filename: \u0026amp;str) -\u0026gt; SqliteConnection { info!(\u0026#34;start establish_connection()\u0026#34;,); let home_dir = home_dir().unwrap_or(\u0026#34;\u0026#34;).to_string(); let database_url = format!(\u0026#34;sqlite://{}/{}\u0026#34;,home_dir.to_string_lossy(), database_filename); SqliteConnection::establish(\u0026amp;database_url) .unwrap_or_else(|_| panic!(\u0026#34;Error connecting to the database: {}\u0026#34;, database_url)) } The database connection is then used as follows:\nuse crate::database::*; ... let mut conn = establish_connection(\u0026#34;tauri_database.db\u0026#34;); ... Model and schema # The model defines the structure and the schema the database table. There is also the possibility to generate the rust objects from the database. I proceeded like this, but I had to adjust certain fields and settings, so here I present the working result.\nExample 2.1 models.rs\nuse chrono::NaiveDateTime; use diesel::{ Insertable, Queryable, Selectable, Table}; use serde::{Deserialize, Serialize}; #[derive(Serialize, Deserialize, Debug, Selectable, Insertable, Queryable)] #[diesel(table_name = crate::schema::document)] pub struct Document { pub id: String, pub subject: String, pub status: String, pub date: String, pub sender_name: Option\u0026lt;String\u0026gt;, pub sender_addr: Option\u0026lt;String\u0026gt;, pub recipient_name: Option\u0026lt;String\u0026gt;, pub recipient_addr: Option\u0026lt;String\u0026gt;, pub from: Option\u0026lt;String\u0026gt;, pub to: Option\u0026lt;String\u0026gt;, pub body: Option\u0026lt;String\u0026gt;, pub document_type: Option\u0026lt;String\u0026gt;, pub metadata: Option\u0026lt;String\u0026gt;, pub category: Option\u0026lt;String\u0026gt;, pub amount: Option\u0026lt;f64\u0026gt;, pub currency: Option\u0026lt;String\u0026gt;, pub template_name: Option\u0026lt;String\u0026gt;, pub doc_data: Option\u0026lt;String\u0026gt;, pub input_path: Option\u0026lt;String\u0026gt;, pub langu: Option\u0026lt;String\u0026gt;, pub num_pages: Option\u0026lt;f64\u0026gt;, pub protocol: Option\u0026lt;String\u0026gt;, pub sub_path: Option\u0026lt;String\u0026gt;, pub filename: Option\u0026lt;String\u0026gt;, pub file_extension: Option\u0026lt;String\u0026gt;, pub file: Option\u0026lt;String\u0026gt;, pub base64: Option\u0026lt;String\u0026gt;, pub ocr_data: Option\u0026lt;String\u0026gt;, pub jpg_file: Option\u0026lt;String\u0026gt;, pub parent_document: Option\u0026lt;String\u0026gt;, pub created_at: String, pub updated_at: String, pub deleted_at: Option\u0026lt;String\u0026gt;, } schema.rs\ntable! { document (id) { id -\u0026gt; Text, subject -\u0026gt; Text, status -\u0026gt; Text, date -\u0026gt; Timestamp, sender_name -\u0026gt; Nullable\u0026lt;Text\u0026gt;, sender_addr -\u0026gt; Nullable\u0026lt;Text\u0026gt;, recipient_name -\u0026gt; Nullable\u0026lt;Text\u0026gt;, recipient_addr -\u0026gt; Nullable\u0026lt;Text\u0026gt;, from -\u0026gt; Nullable\u0026lt;Text\u0026gt;, to -\u0026gt; Nullable\u0026lt;Text\u0026gt;, body -\u0026gt; Nullable\u0026lt;Text\u0026gt;, #[sql_name = \u0026#34;type\u0026#34;] document_type -\u0026gt; Nullable\u0026lt;Text\u0026gt;, metadata -\u0026gt; Nullable\u0026lt;Text\u0026gt;, category -\u0026gt; Nullable\u0026lt;Text\u0026gt;, amount -\u0026gt; Nullable\u0026lt;Double\u0026gt;, currency -\u0026gt; Nullable\u0026lt;Text\u0026gt;, template_name -\u0026gt; Nullable\u0026lt;Text\u0026gt;, doc_data -\u0026gt; Nullable\u0026lt;Text\u0026gt;, input_path -\u0026gt; Nullable\u0026lt;Text\u0026gt;, langu -\u0026gt; Nullable\u0026lt;Text\u0026gt;, num_pages -\u0026gt; Nullable\u0026lt;Double\u0026gt;, protocol -\u0026gt; Nullable\u0026lt;Text\u0026gt;, sub_path -\u0026gt; Nullable\u0026lt;Text\u0026gt;, filename -\u0026gt; Nullable\u0026lt;Text\u0026gt;, file_extension -\u0026gt; Nullable\u0026lt;Text\u0026gt;, file -\u0026gt; Nullable\u0026lt;Text\u0026gt;, base64 -\u0026gt; Nullable\u0026lt;Text\u0026gt;, ocr_data -\u0026gt; Nullable\u0026lt;Text\u0026gt;, jpg_file -\u0026gt; Nullable\u0026lt;Text\u0026gt;, parent_document -\u0026gt; Nullable\u0026lt;Text\u0026gt;, #[sql_name = \u0026#34;createdAt\u0026#34;] created_at -\u0026gt; Timestamp, #[sql_name = \u0026#34;updatedAt\u0026#34;] updated_at -\u0026gt; Timestamp, #[sql_name = \u0026#34;deletedAt\u0026#34;] deleted_at -\u0026gt; Nullable\u0026lt;Timestamp\u0026gt;, } } In this example, more than 32 fields have been defined in the document table. For this case, the features \u0026ldquo;64-column-tables\u0026rdquo; must be set in the diesel: Cargo.toml\n... diesel = { version = \u0026#34;2.1.0\u0026#34;, features = [\u0026#34;sqlite\u0026#34;, \u0026#34;64-column-tables\u0026#34;] } ... In addition, field names that are not defined snake_case or correspond to invalid syntax in rust, e.g. type, must be mapped.\n#[sql_name = \u0026#34;type\u0026#34;] document_type -\u0026gt; Nullable\u0026lt;Text\u0026gt;, Here the database field type is mapped to the rust field document_type.\n3 Selection of data # For the selection of data, a distinction must be made between two variants - on the one hand, a table can be accessed like an \u0026ldquo;object\u0026rdquo;, on the other hand, an SQL-like query is available under DSL. This must be differentiated already when including the libraries.\nExample 3.1 Read a document for a document ID:\nuse crate::database::*; use crate::models::*; use crate::schema; // like document use crate::schema::document::dsl; // like dsl::document use crate::schema::Response; use diesel::prelude::*; use serde_json::json; use tracing::{info, warn, error}; use tracing_subscriber; ... let mut conn = establish_connection(\u0026#34;tauri_database.db\u0026#34;); let my_document = match dsl::document .filter(dsl::id.eq(my_query.id)) .select(Document::as_select()) .first::\u0026lt;Document\u0026gt;(\u0026amp;mut conn) { Ok(record) =\u0026gt; record, Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: format!(\u0026#34;{}\u0026#34;, err), }; } }; ... In the example exactly one document with a certain ID is selected. The fields of the selection are specified in .select(), in the example all fields. The type of the result must be specified after .first and must necessarily match the fields from .select. Here it is very easy to define and select a subset of the fields using a separate structure. The definition of the structure has the advantage that also an object and if necessary a vector to this object can be defined.\nExample 3.2 - select only certain fields: models.rs\n#[derive(Serialize, Deserialize, Debug, Selectable, Queryable)] #[diesel(table_name = crate::schema::document)] pub struct DocumentFile { pub id: String, pub sub_path: Option\u0026lt;String\u0026gt;, pub filename: Option\u0026lt;String\u0026gt;, pub file_extension: Option\u0026lt;String\u0026gt;, pub file: Option\u0026lt;String\u0026gt;, pub base64: Option\u0026lt;String\u0026gt;, } ... let mut conn = establish_connection(\u0026#34;tauri_database.db\u0026#34;); let my_document = match dsl::document .filter(dsl::id.eq(my_query.id)) .select(DocumentFile::as_select()) .first::\u0026lt;DocumentFile\u0026gt;(\u0026amp;mut conn) { Ok(record) =\u0026gt; record, Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: format!(\u0026#34;{}\u0026#34;, err), }; } }; ... An elegant variant for a dynamic selection is the definition query as BoxedDsl. This can be used to combine and dynamically generate order_by() or filter() sorts. In the following example, a URL is parsed dynamically and the selection conditions are built depending on the URL parameters. The notation is along the lines of `solr'.\nFor example 3.3:\nhttp://localhost:8080/get_document?q=body:*Apple*\u0026amp;sort=date%20desc\u0026amp;rows=50 In this example, the string Apple is to be searched for in the field body. The records are sorted by the field date in descending order and the first 50 records are selected.\nExample 3.4:\nuse crate::database::*; use crate::models::*; use crate::schema; use crate::schema::document::dsl; use crate::schema::Response; use diesel::prelude::*; use serde_json::json; use tracing::info; use tracing_subscriber; use url::Url; ... let parsed_url = match Url::parse(\u0026amp;my_query_url) { Ok(result) =\u0026gt; result, Err(err) =\u0026gt; { return Response { dataname: path, data: \u0026#34;[]\u0026#34;.to_string(), error: err.to_string(), }} }; let mut query = dsl::document.into_boxed(); let mut limit = 50; let mut search: String; // = \u0026#34;\u0026#34;.to_string(); //loop via URL parameter for pair in parsed_url.query_pairs() { info!(?pair, \u0026#34;document url pair\u0026#34;); //------------------------------------ if pair.0 == \u0026#34;rows\u0026#34; { //limit of rows parameter match pair.1.parse::\u0026lt;i64\u0026gt;() { Ok(v) =\u0026gt; { limit = v; } _ =\u0026gt; {} }; } //------------------------------------ if pair.0 == \u0026#34;sort\u0026#34; { //sort parameter let mut sort_field_iter = pair.1.split_whitespace(); let sort_field_name = sort_field_iter.next().unwrap_or(r#\u0026#34;\u0026#34;#); let sort_field_order = sort_field_iter.next().unwrap_or(r#\u0026#34;\u0026#34;#); match sort_field_name { \u0026#34;date\u0026#34; =\u0026gt; { if sort_field_order == \u0026#34;desc\u0026#34; { query = query.order_by(dsl::date.desc()); } else { query = query.order_by(dsl::date.asc()); } } \u0026#34;subject\u0026#34; =\u0026gt; { if sort_field_order == \u0026#34;desc\u0026#34; { query = query.order_by(dsl::subject.desc()) } else { query = query.order_by(dsl::subject.asc()) } } \u0026#34;status\u0026#34; =\u0026gt; { if sort_field_order == \u0026#34;desc\u0026#34; { query = query.order_by(dsl::status.desc()); } else { query = query.order_by(dsl::status.asc()); } } \u0026#34;amount\u0026#34; =\u0026gt; { if sort_field_order == \u0026#34;desc\u0026#34; { query = query.order_by(dsl::amount.desc()); } else { query = query.order_by(dsl::amount.asc()); } } _ =\u0026gt; query = query.order_by(dsl::date.desc()), } } //------------------------------------ if pair.0 == \u0026#34;q\u0026#34; { //where parameter let mut filter_field_iter = pair.1.split(\u0026#39;:\u0026#39;); let filter_field_name = filter_field_iter.next().unwrap_or(r#\u0026#34;\u0026#34;#); let filter_field_match = filter_field_iter.next().unwrap_or(r#\u0026#34;\u0026#34;#); //the `*`from the transfer string into placeholder `%`for the selection search = String::from(str::replace(\u0026amp;filter_field_match, \u0026#34;*\u0026#34;, \u0026#34;%\u0026#34;)); match filter_field_name { \u0026#34;body\u0026#34; =\u0026gt; query = query.filter(dsl::body.like(search)), \u0026#34;subject\u0026#34; =\u0026gt; query = query.filter(dsl::subject.like(search)), \u0026#34;status\u0026#34; =\u0026gt; query = query.filter(dsl::status.like(search)), \u0026#34;date\u0026#34; =\u0026gt; query = query.filter(dsl::date.eq(search)), \u0026#34;amount\u0026#34; =\u0026gt; { //Conversion of the transfer string into a number query = query.filter(dsl::amount.eq(search.parse::\u0026lt;f64\u0026gt;().unwrap_or(0_f64)))}, \u0026#34;sender_name\u0026#34; =\u0026gt; query = query.filter(dsl::sender_name.like(search)), \u0026#34;recipient_name\u0026#34; =\u0026gt; query = query.filter(dsl::recipient_name.like(search)), \u0026#34;category\u0026#34; =\u0026gt; query = query.filter(dsl::category.like(search)), _ =\u0026gt; {} }; } } let mut conn = establish_connection(\u0026#34;tauri_database.db\u0026#34;); match query .limit(limit) .filter(dsl::deleted_at.is_null()) .select(DocumentSmall::as_select()) .load::\u0026lt;DocumentSmall\u0026gt;(\u0026amp;mut conn) { Ok(result) =\u0026gt; Response { dataname: path, data: json!(\u0026amp;result).to_string(), error: String::from(\u0026#34;\u0026#34;), }, Err(err) =\u0026gt; Response { dataname: path, data: \u0026#34;[]\u0026#34;.to_string(), error: err.to_string(), }, } ... The coding is not completely dynamic, because the used fields must have been defined in the structures of the database schema.rs and models.modelrs. Only the selection statemnt is dynamically assembled. In the example all conversions were also checked for validity by match, so that no panic is triggered, especially with transfer values from users.\nfunction debug_query extracts the statement for the output # There is also a function to output the generated SQL statement. In this case you separate selection and execution.\nExample 3.5:\n... use diesel::debug_query; use crate::diesel::sqlite::Sqlite; use diesel::prelude::*; use tracing::{error, info, warn}; use tracing_subscriber; ... let mut conn = establish_connection(\u0026#34;tauri_database.db\u0026#34;); let exec_query = dsl::document .filter(dsl::id.eq(my_query.id)) .select(DocumentFile::as_select()); info!(\u0026#34;debug sql\\n{}\u0026#34;, debug_query::\u0026lt;Sqlite, _\u0026gt;(\u0026amp;exec_query)); let my_document = match exec_query.first::\u0026lt;DocumentFile\u0026gt;(\u0026amp;mut conn) { Ok(record) =\u0026gt; record, Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: format!(\u0026#34;{}\u0026#34;, err), }; } }; The function debug_query extracts the statement for the output. Afterwards the execution and further processing of the data takes place.\nsql functions count(*) or sum(amount) # The standard functions in SQL for count(*) or sum(x) are available in diesel. But I only got the function count(*) to work, so here is the variant as native sql.\nExample 3.6:\n... use crate::diesel::sqlite::Sqlite; use crate::schema::document::dsl; use diesel::debug_query; use diesel::prelude::*; use diesel::dsl::sql; use diesel::sql_types::Double; ... let operation: \u0026amp;str; if path.as_str() == \u0026#34;chart_count\u0026#34; { //parameter to control statement operation = \u0026#34;count(id) AS count\u0026#34;; //count documents } else { operation = \u0026#34;sum(amount) AS sum\u0026#34;; //sum the amount } let exec_query = document::table .into_boxed() .filter( dsl::deleted_at .is_null() .and(dsl::date.le(local_start.to_string())) //date from/to start datetime .and(dsl::date.ge(local_end.to_string())) .and(dsl::category.like(format!(\u0026#34;%{}%\u0026#34;, query))) //query contains the selected category .and(dsl::amount.is_not_null()), ) .select(sql::\u0026lt;Double\u0026gt;(operation)); info!(\u0026#34;debug first sql\\n{}\u0026#34;, debug_query::\u0026lt;Sqlite, _\u0026gt;(\u0026amp;exec_query)); let y_value = exec_query.first::\u0026lt;f64\u0026gt;(\u0026amp;mut conn).unwrap_or(0_f64); It is a bit strange, but in the where condition the datatype is required to be dubble, because my field amount is of this type and the return value is f64 - the values are converted between FromSql/ToSql and the application.\n4 Read PDF file to base64 conversion # In my example the name and path of the PDF file is in the SQLite database. In the examples shown above the file name from field file and also the path from field sub_path is read to the document ID exactly for one document. The files are in the home directory in a main directory MAIN_PATH belonging to the program and in this then in a FILE_PATH.\nExample 4.1 Definition of constants for the directories to be used in the home directory: database.rs\npub const MAIN_PATH: \u0026amp;str = r#\u0026#34;archive\u0026#34;#; pub const DATABASE_NAME: \u0026amp;str = r#\u0026#34;tauri_database.db\u0026#34;#; pub const FILE_PATH: \u0026amp;str = r#\u0026#34;data\u0026#34;#; After the selection of the data from the database the following determination of the home directory takes place:\nExample 4.2:\ninfo!(?my_document.id, \u0026#34;select document id\u0026#34; ); info!(?my_document.sub_path, \u0026#34;select document subpath\u0026#34; ); use home::home_dir; let home_dir = match home_dir() { Some(result) =\u0026gt; result, None =\u0026gt; { return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: r#\u0026#34;no pdf found\u0026#34;#.to_string(), }; } }; let filename = my_document.file.unwrap_or(\u0026#34;\u0026#34;.to_string()); if filename.is_empty() { return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: r#\u0026#34;no pdf found\u0026#34;#.to_string(), }; } //Build PDF Filenames let pdf_file = format!( \u0026#34;{}/{}/{}/{}{}\u0026#34;, home_dir.to_str().unwrap_or(\u0026#34;\u0026#34;).to_string(), MAIN_PATH, FILE_PATH, my_document.sub_path.unwrap_or(\u0026#34;\u0026#34;.to_string()), filename ); info!(?pdf_file, \u0026#34;select document file\u0026#34;); At the end pdf_file contains the complete path for accessing the file, so that now the file can be opened and loaded as binary into a variable list_of_chunks of type Vec\u0026lt;u8\u0026gt;.\nExample 4.3:\n//open file by name let mut file = match std::fs::File::open(\u0026amp;pdf_file) { Ok(file) =\u0026gt; file, Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: format!(\u0026#34;{}\u0026#34;, err), }; } }; info!(?filename, \u0026#34;open file by name \u0026#34;); //Read PDF as binary file use std::io::{self, Read, Seek, SeekFrom}; let mut list_of_chunks = Vec::new(); let chunk_size = 0x4000; loop { let mut chunk = Vec::with_capacity(chunk_size); let n = match file .by_ref() .take(chunk_size as u64) .read_to_end(\u0026amp;mut chunk) { Ok(data) =\u0026gt; data, Err(err) =\u0026gt; { info!(?err, \u0026#34;error file read\u0026#34;); break; } }; if n == 0 { break; } for ele in chunk { list_of_chunks.push(ele); } if n \u0026lt; chunk_size { break; } } The data from the PDF file is now in list_of_chunks and is converted to base64 and returned.\nExample 4.4:\nif list_of_chunks.len() != 0 { //binary encode to base64 use base64::{engine::general_purpose, Engine as _}; let base64_data = general_purpose::STANDARD_NO_PAD.encode(list_of_chunks); return Response { dataname: data, data: json!(\u0026amp;base64_data).to_string(), error: \u0026#34;\u0026#34;.to_string(), }; 5 Communication between Tauri and Vue # Finally an info about the communication between Tauri and Vue. For this I can recommend the very good documentation at Rob Donnelly. I have implemented this variant. The transfer from/to Vue is always done as string in the end, so all structures have to be converted in and out as json string.\nExample 5.1 Vue javascript file to call Tauri\nimport { invoke } from \u0026#34;@tauri-apps/api/tauri\u0026#34;; ... invoke(\u0026#34;js2rs\u0026#34;, { message: JSON.stringify({ path: \u0026#34;category\u0026#34;, query: \u0026#34;?json=true\u0026#34;, data: \u0026#34;category\u0026#34;, }), }); ... In my example, the message field is transmitted as a JSON string and then needs to be parsed in Tauri into the path, query and data components.\nExample 5.2 Tauri command for the invoke:\n#[tauri::command] async fn js2rs(message: String, state: tauri::State\u0026lt;\u0026#39;_, AsyncProcInputTx\u0026gt;) -\u0026gt; Result\u0026lt;(), String\u0026gt; { let mut sub_message = message.clone(); sub_message.truncate(50); info!(?sub_message, \u0026#34;js2rs\u0026#34;); let async_proc_input_tx = state.inner.lock().await; async_proc_input_tx.send(message).await.map_err(|e| { println!(\u0026#34;{}\u0026#34;, e.to_string()); e.to_string() }) } Here the string is sent into the channel async_proc_input_tx to be processed one after the other.\nExample 5.2.\nasync fn async_process_model( mut input_rx: mpsc::Receiver\u0026lt;String\u0026gt;, output_tx: mpsc::Sender\u0026lt;String\u0026gt;, ) -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error + Send + Sync\u0026gt;\u0026gt; { while let Some(input) = input_rx.recv().await { let mut parse_error = false; let my_input_data: Receiver = match serde_json::from_str(input.as_str()) { Ok(data) =\u0026gt; data, Err(err) =\u0026gt; { parse_error = true; let my_output_data = Response { dataname: \u0026#34;\u0026#34;.to_string(), data: \u0026#34;[]\u0026#34;.to_string(), error: err.to_string() }; let output = json!(my_output_data).to_string(); match output_tx.send(output).await { _ =\u0026gt; {} } Receiver { path: \u0026#34;\u0026#34;.to_string(), query: \u0026#34;\u0026#34;.to_string(), data: \u0026#34;[]\u0026#34;.to_string() } } }; if !parse_error { let my_output_data: Response = message_handler(my_input_data.path, my_input_data.query, my_input_data.data).await; let output = json!(my_output_data).to_string(); match output_tx.send(output).await { _ =\u0026gt; {} } } } Ok(()) } There are the following structures in my example that are converted between Tauri and Vue:\nExample 5.3. from schema.rs.\n#[derive(serde::Serialize, Debug)] pub struct Response { pub dataname: String, pub data: String, pub error: String, } #[derive(serde::Serialize, serde::Deserialize, Debug)] pub struct Receiver { pub path: String, pub query: String, pub data: String, } 6 Data structures in the Tauri server app_data # In the Tauri - Vue communication, the tauri-handler contains a Stauts parameter that controls the processing of the channel. Similarly, in my application I need central information that the server manages and that should be available in the handlers, i.e., read, used or changed there and persistently saved. I decided to use a json file in the home directory. With the start of the server the data is read or, if the file does not exist, initialized and if the user maintains the data from the Vue application, the data should be written into the corresponding file.\nFirst we need the data structure and the functions for reading, changing and saving.\nExample 6.1 main.rs\n#[derive(serde::Serialize, serde::Deserialize, Debug)] pub struct AppData { pub main_path: String, pub email: String, pub name: String, pub clone_dir: String, } impl AppData { //constructor from `app_data` as clone() pub fn new(app_data: \u0026amp;AppData) -\u0026gt; Self { info!(\u0026#34;AppData new()\u0026#34;); AppData { main_path: app_data.main_path.clone(), email: app_data.email.clone(), name: app_data.name.clone(), clone_dir: app_data.clone_dir.clone(), } } //constructor from file pub fn init_app_data() -\u0026gt; Self { info!(\u0026#34;AppData init_app_data()\u0026#34;); let home_dir = home_dir().unwrap_or(\u0026#34;\u0026#34;.into()); let file_and_path = format!( \u0026#34;{}/{}\u0026#34;, home_dir.to_str().unwrap_or(\u0026#34;\u0026#34;).to_string(), database::APP_DATA_FILENAME ); use std::fs::read_to_string; let app_data_string = read_to_string(file_and_path).unwrap_or(\u0026#34;\u0026#34;.to_string()); let app_data = match serde_json::from_str(\u0026amp;app_data_string) { Ok(result) =\u0026gt; result, Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); AppData { main_path: database::MAIN_PATH.to_string(), email: \u0026#34;\u0026#34;.to_string(), name: \u0026#34;\u0026#34;.to_string(), clone_dir: \u0026#34;\u0026#34;.to_string(), } } }; return app_data; } pub fn set(\u0026amp;mut self, main_path: String, email: String, name: String, clone_dir: String) { self.main_path = main_path; self.email = email; self.name = name; self.clone_dir = clone_dir; self.save_me(); } pub fn save_me(\u0026amp;self) { info!(\u0026#34;AppData save_me()\u0026#34;); let home_dir = home_dir().unwrap_or(\u0026#34;\u0026#34;.into()); let file_and_path = format!( \u0026#34;{}/{}\u0026#34;, home_dir.to_str().unwrap_or(\u0026#34;\u0026#34;).to_string(), database::APP_DATA_FILENAME ); let app_data_json = json!(self).to_string(); match fs::write(file_and_path, app_data_json) { Ok(_) =\u0026gt; {} Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); } }; } } There are two constuctor here - once with new(data) a new object is created over the passed data, on the other hand with the function init_app_data(), here we read from the file and generate the object. In both cases the instance of AppData is returned.\nThe file itself with the data from AppData is always read or written into the home directory with the name defined as from APP_DATA_FILENAME. There is now the function set(data) which also calls save_me() and finally saves the data as a json file.\nIn the main routine in the tauri server, the object can be passed via manage() and is then available optinally as a parameter in dan tauri-handlers.\nExample 6.2:\nfn main() { tracing_subscriber::fmt::init(); generate_directory_database(); let (async_proc_input_tx, async_proc_input_rx) = mpsc::channel(1); let (async_proc_output_tx, mut async_proc_output_rx) = mpsc::channel(1); tauri::Builder::default() .manage(AsyncProcInputTx { // Mutex to manage inner: Mutex::new(async_proc_input_tx), }) .manage(AppData::init_app_data()) // AppData to manage .invoke_handler(tauri::generate_handler![js2rs]) // tauri handler .setup(|app| { tauri::async_runtime::spawn(async move { async_process_model(async_proc_input_rx, async_proc_output_tx).await }); let app_handle = app.handle(); tauri::async_runtime::spawn(async move { loop { if let Some(output) = async_proc_output_rx.recv().await { rs2js(output, \u0026amp;app_handle); } } }); Ok(()) }) .run(tauri::generate_context!()) .expect(\u0026#34;error while running tauri application\u0026#34;); } The tauri handler js2rs can now receive the new parameter:\nExample 6.2:\n#[tauri::command] async fn js2rs( message: String, state: tauri::State\u0026lt;\u0026#39;_, AsyncProcInputTx\u0026gt;, app_data: tauri::State\u0026lt;\u0026#39;_, AppData\u0026gt;, ) -\u0026gt; Result\u0026lt;(), String\u0026gt; { let mut sub_message = message.clone(); sub_message.truncate(50); info!(?sub_message, \u0026#34;js2rs\u0026#34;); let async_proc_input_tx = state.inner.lock().await; async_proc_input_tx .send((message, AppData::new(app_data.inner()))) .await .map_err(|e| { println!(\u0026#34;{}\u0026#34;, e.to_string()); e.to_string() }) } Because at this point processing does not yet take place, but the data is first passed into a channel for asynchronous processing, the Message and AppData must be passed as tuples and the type of the Input parameter must also be adjusted.\nExample 6.2:\n... struct AsyncProcInputTx { inner: Mutex\u0026lt;mpsc::Sender\u0026lt;(String, AppData)\u0026gt;\u0026gt;, } ... async fn async_process_model( mut input_rx: mpsc::Receiver\u0026lt;(String, AppData)\u0026gt;, //input tuple with AppData output_tx: mpsc::Sender\u0026lt;String\u0026gt;, ) -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error + Send + Sync\u0026gt;\u0026gt; { while let Some((message, app_data)) = input_rx.recv().await { let mut parse_error = false; let my_message_data: Receiver = match serde_json::from_str(message.as_str()) { Ok(data) =\u0026gt; data, Err(err) =\u0026gt; { parse_error = true; let my_output_data = Response { dataname: \u0026#34;\u0026#34;.to_string(), data: \u0026#34;[]\u0026#34;.to_string(), error: err.to_string(), }; let output = json!(my_output_data).to_string(); match output_tx.send(output).await { _ =\u0026gt; {} } Receiver { path: \u0026#34;\u0026#34;.to_string(), query: \u0026#34;\u0026#34;.to_string(), data: \u0026#34;[]\u0026#34;.to_string(), } } }; if !parse_error { let my_output_data: Response = message_handler( app_data, //app_data as parameter my_message_data.path, my_message_data.query, my_message_data.data, ) .await; let output = json!(my_output_data).to_string(); match output_tx.send(output).await { _ =\u0026gt; {} } } } Ok(()) } To do this, the channel and also the async_process_model function must be adapted accordingly and the app_Data parameter extended.\nIn the tauri handler itself the object AppData can then be used. In my example there is user for reading and save_user for saving from the application.\nExample 6.3.:\n#[tauri::command(async)] async fn message_handler( //window: tauri::Window, //database: tauri::State\u0026lt;\u0026#39;_, Database\u0026gt;, mut app_data: AppData, path: String, query: String, data: String, ) -\u0026gt; Response { let message = format!( \u0026#34;path: {}, query: {}, data: {}\u0026#34;, path.as_str().clone(), query.as_str().clone(), data.as_str().clone() ); info!(message, \u0026#34;message_handler\u0026#34;); io::stdout().flush().unwrap(); match path.as_str() { //---- \u0026#34;user\u0026#34; =\u0026gt; { let home_dir = home_dir().unwrap(); let message = format!(\u0026#34;Your home directory, probably: {}\u0026#34;, home_dir.display()); info!(message, \u0026#34;message_handler\u0026#34;); let my_data = json!( UserData { email: app_data.email, name: app_data.name, path_name: app_data.main_path, clone_path: app_data.clone_dir, avatar: \u0026#34;\u0026#34;.to_string() }).to_string(); Response { dataname: \u0026#34;me\u0026#34;.to_string(), data: my_data, error: \u0026#34;\u0026#34;.to_string(), } } //---- \u0026#34;save_user\u0026#34; =\u0026gt; { let my_save_user_data: SaveUserCommand = match serde_json::from_str(\u0026amp;data) { Ok(result) =\u0026gt; result, Err(err) =\u0026gt; { error!(?err, \u0026#34;Error: \u0026#34;); return Response { dataname: data, data: \u0026#34;[]\u0026#34;.to_string(), error: format!(\u0026#34;{}\u0026#34;, err), }; } }; app_data.set( my_user_data.path_name.clone(), my_user_data.email.clone(), my_user_data.name.clone(), my_user_data.clone_path.clone(), ); let my_data = json!(my_user_data).to_string(); Response { dataname: \u0026#34;me\u0026#34;.to_string(), data: my_data, error: \u0026#34;\u0026#34;.to_string(), } } ... } } The save_user for the function set(data) off, which then also writes the data to the home directory, so that after a restart this data can be read.\nOn the client side in Vue, simply start the invoke with the data:\nExample 6.4 MainLayout.vue:\nimport { invoke } from \u0026#34;@tauri-apps/api/tauri\u0026#34;; ... saveDialogMe() { console.log(`MainLayout saveDialogMe()`); this.me.name = this.dialogMeData.name || \u0026#34;\u0026#34;; this.me.email = this.dialogMeData.email || \u0026#34;\u0026#34;; this.me.path_name = this.dialogMeData.path_name || \u0026#34;\u0026#34;; this.me.clone_path = this.dialogMeData.clone_path || \u0026#34;\u0026#34;; this.me.avatar = this.getGravatarURL(this.me.email); invoke(\u0026#34;js2rs\u0026#34;, { message: JSON.stringify({ path: \u0026#34;save_user\u0026#34;, query: \u0026#34;\u0026#34;, data: JSON.stringify(this.me), })}); this.dialogMe = false; }, ... The avatar is determined on the client, that must be released for the access in the Tauri tauri.conf.json.\n7 Conclusion # Rust is like any other programming language: you have to study it to understand it. Some features allow elegant programming, others are incomprehensible and make it difficult to use. There is always light and shadow. For the error messages of the compiler you quickly get a feeling what you did wrong, it is merciless. The language could be more understandable and coherent in my opinion, other programming languages are much better.\nDynamic parameters and also the forced error handling are really good. It creates a robust program, even if it takes a little longer. The channels reminded me of golang, but the powerful promise from JavaScript is not nearly reached.\nSome of the libraries are still in their infancy, it will take some time to establish stability for productive use, but the path is the right one. In some places, one wishes for better documentation and more examples - which is what I tried to do with this post.\nThanks to the hardworking developers of dieseland tauri- it was fun and I will continue down the path because you can\u0026rsquo;t process media data in Electron for example and that runs in tauri, that\u0026rsquo;s my next project.\nIndex\n"}]